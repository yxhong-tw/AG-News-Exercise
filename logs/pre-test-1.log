2023-07-29 04:25:29,654 - initialize - INFO - Initializing seed to 48763 successfully.
2023-07-29 04:25:30,503 - initialize - INFO - Initializing device to cuda successfully.
2023-07-29 04:25:30,518 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-07-29 04:25:31,333 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1" 200 0
2023-07-29 04:25:32,520 - initialize - INFO - Initializing model to BertWithNN successfully.
2023-07-29 04:25:32,981 - initialize - INFO - Initializing optimizer to Adam successfully.
2023-07-29 04:25:32,981 - initialize - INFO - Initializing scheduler to ReduceLROnPlateau successfully.
2023-07-29 04:25:33,287 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:25:33,381 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:25:33,383 - initialize - INFO - Initializing train dataloader successfully.
2023-07-29 04:25:33,695 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:25:33,742 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:25:33,744 - initialize - INFO - Initializing validation dataloader successfully.
2023-07-29 04:25:34,042 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:25:34,091 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:25:34,092 - initialize - INFO - Initializing test dataloader successfully.
2023-07-29 04:25:34,092 - initialize - INFO - Initialize all parameters successfully.
2023-07-29 04:25:34,098 - initialize - INFO - Details of all parameters: 
{'device': device(type='cuda'), 'model': BertWithNN(
  (lm): Bert(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (classifier): Classifier(
    (classifier): Sequential(
      (linear_0): Linear(in_features=768, out_features=384, bias=True)
      (linear_1): Linear(in_features=384, out_features=192, bias=True)
      (linear_2): Linear(in_features=192, out_features=4, bias=True)
      (relu_2): ReLU()
    )
  )
  (criterion): CrossEntropyLoss()
), 'trained_epoch': -1, 'test_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x000001A57D35A108>, 'optimizer': Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0
), 'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001A57EC115C8>, 'train_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x000001A564793388>, 'validation_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x000001A57E936888>}
2023-07-29 04:25:43,457 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   0   | train |    1/3     | 0:00:09\ 0:00:18 | 1.4601283 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:25:53,359 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   0   | train |    2/3     | 0:00:19\ 0:00:09 | 1.4344092 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:25:56,365 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   0   | train |    3/3     | 0:00:22\ 0:00:00 | 1.4183709 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-------+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF |  MaE  |
+-----+-----+-----+------+-----+-----+-----+-------+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.486 |
+-----+-----+-----+------+-----+-----+-----+-------+

2023-07-29 04:25:56,368 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   0   | train |    3/3     | 0:00:22\ 0:00:00 | 0.1772964 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-------+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF |  MaE  |
+-----+-----+-----+------+-----+-----+-----+-------+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.486 |
+-----+-----+-----+------+-----+-----+-----+-------+

2023-07-29 04:26:00,623 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   0   | validate |    1/3     | 0:00:04\ 0:00:08 | 1.3877356 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:04,766 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   0   | validate |    2/3     | 0:00:08\ 0:00:04 | 1.3879139 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:05,874 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   0   | validate |    3/3     | 0:00:09\ 0:00:00 | 1.3874846 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:05,877 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   0   | validate |    3/3     | 0:00:09\ 0:00:00 | 0.1734356 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:12,461 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   0   | test  |    1/3     | 0:00:04\ 0:00:09 | 1.3878288 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:16,828 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   0   | test  |    2/3     | 0:00:08\ 0:00:04 | 1.3879554 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:17,936 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   0   | test  |    3/3     | 0:00:10\ 0:00:00 | 1.3874017 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:17,939 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   0   | test  |    3/3     | 0:00:10\ 0:00:00 | 0.1734252 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:28,244 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   1   | train |    1/3     | 0:00:10\ 0:00:20 | 1.3881278 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:38,634 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   1   | train |    2/3     | 0:00:20\ 0:00:10 | 1.3872111 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:41,650 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   1   | train |    3/3     | 0:00:23\ 0:00:00 | 1.3869055 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:41,653 - utils - INFO - 
+-------+-------+------------+------------------+-----------+-------+
| epoch | stage | iterations |       time       |   loss    |  lr   |
+-------+-------+------------+------------------+-----------+-------+
|   1   | train |    3/3     | 0:00:23\ 0:00:00 | 0.1733632 | 1e-05 |
+-------+-------+------------+------------------+-----------+-------+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.5 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:45,910 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   1   | validate |    1/3     | 0:00:04\ 0:00:08 | 1.3862944 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:50,068 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   1   | validate |    2/3     | 0:00:08\ 0:00:04 | 1.3862944 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:51,168 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   1   | validate |    3/3     | 0:00:09\ 0:00:00 | 1.3862944 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:51,170 - utils - INFO - 
+-------+----------+------------+------------------+-----------+----+
| epoch |  stage   | iterations |       time       |   loss    | lr |
+-------+----------+------------+------------------+-----------+----+
|   1   | validate |    3/3     | 0:00:09\ 0:00:00 | 0.1732868 |    |
+-------+----------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:26:57,634 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    1/3     | 0:00:04\ 0:00:09 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:02,016 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    2/3     | 0:00:08\ 0:00:04 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:03,112 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    3/3     | 0:00:10\ 0:00:00 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:03,115 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    3/3     | 0:00:10\ 0:00:00 | 0.1732868 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:32,622 - initialize - INFO - Initializing seed to 48763 successfully.
2023-07-29 04:27:33,448 - initialize - INFO - Initializing device to cuda successfully.
2023-07-29 04:27:33,471 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): huggingface.co:443
2023-07-29 04:27:34,574 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1" 200 0
2023-07-29 04:27:36,326 - initialize - INFO - Initializing model to BertWithNN successfully.
2023-07-29 04:27:36,938 - initialize - INFO - Initializing optimizer to Adam successfully.
2023-07-29 04:27:36,938 - initialize - INFO - Initializing scheduler to ReduceLROnPlateau successfully.
2023-07-29 04:27:37,589 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:27:37,638 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:27:37,639 - initialize - INFO - Initializing train dataloader successfully.
2023-07-29 04:27:38,290 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:27:38,334 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:27:38,334 - initialize - INFO - Initializing validation dataloader successfully.
2023-07-29 04:27:41,465 - initialize - INFO - Load checkpoint from checkpoint path successfully.
2023-07-29 04:27:41,780 - urllib3.connectionpool - DEBUG - https://huggingface.co:443 "HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1" 200 0
2023-07-29 04:27:41,831 - initialize - INFO - Initializing formatter to AGNewsFormatter successfully.
2023-07-29 04:27:41,832 - initialize - INFO - Initializing test dataloader successfully.
2023-07-29 04:27:41,833 - initialize - INFO - Initialize all parameters successfully.
2023-07-29 04:27:41,838 - initialize - INFO - Details of all parameters: 
{'device': device(type='cuda'), 'model': BertWithNN(
  (lm): Bert(
    (bert): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
              (intermediate_act_fn): GELUActivation()
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (classifier): Classifier(
    (classifier): Sequential(
      (linear_0): Linear(in_features=768, out_features=384, bias=True)
      (linear_1): Linear(in_features=384, out_features=192, bias=True)
      (linear_2): Linear(in_features=192, out_features=4, bias=True)
      (relu_2): ReLU()
    )
  )
  (criterion): CrossEntropyLoss()
), 'trained_epoch': 1, 'test_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x0000021A12C6DE48>, 'optimizer': Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 1e-05
    maximize: False
    weight_decay: 0
), 'scheduler': <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x0000021A2FAE3BC8>, 'train_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x0000021A4CB07408>, 'validation_dataloader': <torch.utils.data.dataloader.DataLoader object at 0x0000021A4CAEBFC8>}
2023-07-29 04:27:43,507 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    1/3     | 0:00:01\ 0:00:03 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:44,299 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    2/3     | 0:00:02\ 0:00:01 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:44,496 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    3/3     | 0:00:02\ 0:00:00 | 1.3862944 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

2023-07-29 04:27:44,499 - utils - INFO - 
+-------+-------+------------+------------------+-----------+----+
| epoch | stage | iterations |       time       |   loss    | lr |
+-------+-------+------------+------------------+-----------+----+
|   1   | test  |    3/3     | 0:00:02\ 0:00:00 | 0.1732868 |    |
+-------+-------+------------+------------------+-----------+----+
+-----+-----+-----+------+-----+-----+-----+-----+
| MiP | MiR | MiF | MiE  | MaP | MaR | MaF | MaE |
+-----+-----+-----+------+-----+-----+-----+-----+
| 0.0 | 0.0 | 0.0 | 0.75 | 0.0 | 0.0 | 0.0 | 0.0 |
+-----+-----+-----+------+-----+-----+-----+-----+

